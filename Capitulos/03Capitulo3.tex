%---------------------------------------------------------------------
%
%                          Capítulo 3
%
%---------------------------------------------------------------------

\chapter{Sustracción de Imagenes}
\label{cap3}

\begin{FraseCelebre}
\begin{Frase}
%  weon \\
%  que chotas
\end{Frase}
\begin{Fuente}
\end{Fuente}
\end{FraseCelebre}

%\begin{resumen}
%...
%\end{resumen}


%-------------------------------------------------------------------
\section{Introducción}
%-------------------------------------------------------------------
\label{cap3:sec:introduccion}

En décadas recientes, la observación de eventos transientes ha tenido un auge 
gracias a wide-field time-domain surveys como PS1 \citep{Chambers_2016}, 
ZTF  \citep{Bellm_2019}, y ATLAS \citep{Tonry_2018}. Todos ellos utilizan 
la sustracción de imágenes (DIA) como método de identificación y extracción 
de curvas de luz de los objetos observados. 

Las primeras propuestas del método de sustracción de imágenes fueron hechas 
en \citep{Phillips_1995} y \citep{Tomaney_1996}, proponiendo el 
uso de un kernel de convolución para hacer coincidir la PSF entre 
dos imágenes. No obstante, su método describe la necesidad de determinar 
la PSF para cada estrella brillante aislada, lo cual resultaba lento, 
ineficiente y poco robusto \citep{Angulo_2025}. 

Sin embargo, no fue hasta las implementaciones de \citep{Kochanski_1996}, 
\citep{Alard_1998}, y \citep{Alard_2000} que el método se volvió más 
robusto, eficiente y de rápida implementación. Algunos de los paquetes 
más recientes que siguen utilizando los mismos principios de la sustracción 
de imágenes son Hotpants \citep{Becker_hotpants_2015}, ZOGY 
\citep{Zackay_2016}y SFFT \citep{Hu_2022}.


La sustracción de una imagen respecto a otra permite identificar diferencias entre ellas, 
lo cual resulta especialmente útil en diversas disciplinas como la meteorología, 
la medicina, el análisis de patrones o el estudio del crecimiento urbano. 
En astronomía, técnicas como el ajuste de la función de dispersión puntual (PSF) 
y la sustracción de imágenes son esenciales para detectar fenómenos astronómicos 
cuya intensidad varía con el tiempo, como ocurre con las estrellas variables 
o los eventos transientes.

Este método de detección de variabilidad resulta particularmente valioso en el estudio 
de cúmulos abiertos y globulares. Su implementación facilita la identificación de 
estrellas variables incluso en regiones densamente pobladas, donde otras técnicas 
fotométricas suelen tener dificultades, 
especialmente cerca del centro del cúmulo. \citep{TRIFFID_observations2013}.

Existe una variedad moderada de paquetes de 
software (PSFMatch \citep{phil_dav_PSFMatch_95}; DANDIA \citep{Bramich_2008}; ZOGY \citep{Zackay_2016};  
CrossConv \citep{YuanAkerlof_CrossConv_2008}.) 
que implementan técnicas de sustracción de imágenes.
En nuestro caso, implementaremos la sustracción de imágenes directamente mediante el uso del 
paquete ISIS \citep{Alard_1998} sobre nuestras observaciones realizadas 
en el Observatorio Astronómico Nacional de la Sierra de San Pedro Mártir. 

Si bien tratar directamente con el programa viene con sus complicaciones, 
queremos realizar una valoración sobre otras implementaciones hechas en un 
más alto nivel de código e incluso de software privado. 

En todos los métodos se toma una imagen de referencia R y una de ciencia I, 
la cual puede ser aproximadamente modelada como: 

$$ I \approx R \ast K + B_{kg} $$

para un fondo $B_{kg}$ y un kernel $K$.

De forma que la imagen óptima de sustracción queda como:

$$ D = I - (R \ast K + B_{kg}) $$

Los distintos métodos difieren principalmente en su forma de modelar el kernel K. 

\begin{itemize}
\item En ISIS \citep{Alard_1998} el kernel $K$ es descompuesto como la suma de funciones analiticas lineales.
        $$K(u,v) = \sum_{n}a_nK_n(u,v)$$ donde $$K_n(u,v)=e^{\frac{-(u^2+v^2)}{2\sigma_k^2}}u_iv_i$$
\item En DANDIA \citep{Bramich_2008} el kernel $K$ es descompuesto como una malla de píxeles discretos.
\end{itemize}


ISIS es un paquete de fotometría especializado en la detección de estrellas 
variables en campos moderadamente densos, como se indica y es puesto en 
práctica en su manual.

La serie de pasos realizados por ISIS para la detección de estrellas 
variables corresponden primero a la alineación del conjunto de observaciones 
del campo deseado, para después generar una imagen de referencia con un 
buen signal-to-noise, tomando un pequeño conjunto de las imágenes con 
mejor seeing de nuestras observaciones. Posteriormente se aplica una 
convolución entre la referencia y cada una de las imágenes de ciencia, 
obteniendo el kernel que caracteriza las condiciones de seeing. 
La imagen de referencia convolucionada para igualar el seeing se 
sustrae a la de ciencia, dando como resultado una serie de imágenes 
sustraídas, donde se pueden observar residuos correspondientes a variaciones 
de flujo entre las dos imágenes. 

%-------------------------------------------------------------------
\section{Point Spread Function (PSF)}
%-------------------------------------------------------------------
\label{cap3:sec:psf}

Definimos la Point Spread Function (PSF) como la respuesta de un sistema de cámara a 
una fuente puntual (un impulso). 

En teoría se espera que la luz de un círculo en la imagen estaría uniformemente 
distribuida, pudiendo ser modelada como una función pillbox, definida como: 

$$
h(x,y) = \begin{cases} 
\frac{4}{\pi b^2}, & x^2 + y^2 \leq \frac{b^2}{4} \\
0, & \text{otherwise}
\end{cases}
$$

Sin embargo, la energía emitida por el objeto que observamos no llega en su totalidad a nuestro detector. 
En la práctica, intervienen una variedad de factores y la distribución de luz en el circulo difuminado no va a 
ser constante. Debido a la difracción, aberracion del lente y 
sensibilidad de la imagen (pixeles), la PSF aparece como una función gaussiana.

$$
h(x,y) = \frac{1}{2\pi\sigma^2}e^{-\frac{x^2 + y^2}{2\sigma^2}}
$$


Al modelar la PSF se desea saber la forma en la que un sistema óptico contribuye y 
modifica las observaciones, permitiendo despreciar dichas inexactitudes 
en la medida de lo posible para representar el objeto de observación de una 
manera mas fiel. La teoría detrás de estas diferencias corresponde al comportamiento 
de las ondas electromagnéticas y la propagación de la luz, en especifico el 
análisis de difracción.

\figura{PSF/Convolution_Illustrated_eng.png}{width=.5\textwidth}{fig:Convolution_Illustrated_eng;}%
{ \href{https://commons.wikimedia.org/wiki/File:Convolution_Illustrated_eng.png}{Efecto de convolucion con PSF. Default007, Public domain, via Wikimedia Commons}} 

Para explicarlas se recurre al principio de Huygens-Fresnel, el cual indica que 
cada punto en un frente de onda puede ser considerado como una propia perturbación 
secundaria, dando paso a ondas esféricas.

% figura Huygens-Fresnel
\figura{PSF/Huygens-Fresnel}{width=.9\textwidth}{fig:Huygens-Fresnel;}%
{Difracción de ondas Huygens y Fresnel} 

De esta forma, el frente de onda siguiente corresponde al envolvente de todas las 
perturbaciones, donde las ondas secundarias también interfieren.

En el caso ideal, podemos definir como imagen perfecta aquella que se ve 
limitada únicamente por la difracción debida al sistema óptico. En este caso, 
conocemos de forma precisa la PSF, para una apertura circular corresponde el 
patron de Airy. Así que simplemente se tendría que sustraer la PSF conocida 
de la imagen, dejando como resultado el objeto debajo.

A pesar de conocer la teoría sobre el comportamiento de la luz, el problema 
y la causa de los errores viene de la intervención de las herramientas que 
usamos para capturarla.
El primer obstáculo entre la fuente de luz y nuestra imagen es el lente. 
Al no existir lentes perfectos, las imperfecciones y aberraciones hacen 
que el frente de onda refractado no sea esférico ideal, evitando que los 
rayos converjan perfectamente en un punto.



%-------------------------------------------------------------------
\section{Registro e Interpolación Astrométrica}
%-------------------------------------------------------------------
\label{cap3:sec:interp}

 Un proceso de vital importancia para el correcto funcionamiento de los pasos 
 posteriores implementados con ISIS es el registro e interpolación astrométrica 
 de cada una de las imágenes. Este proceso consiste en ajustar las imágenes 
 para que estén alineadas espacialmente y se adapten al mismo sistema de 
 coordenadas, lo que facilita su comparación.
El registro astrométrico se encarga de alinear las imágenes, asegurando que 
todas compartan un sistema de coordenadas común. Posteriormente, la interpolación 
astrométrica adapta las imágenes registradas a este sistema, garantizando 
que los píxeles de cada imagen correspondan a las mismas posiciones en el cielo.

Es común que el conjunto de imágenes de observación de un campo pueda presentar 
variaciones debido a distintos factores. La naturaleza de estas variaciones 
puede corresponder al centrado, orientación y escala de las imágenes. \citep{Alard_1998}.  
Entre las distintas fuentes de inconsistencia de las imágenes tomadas en 
un observatorio, podemos mencionar fallos del guiador, condiciones 
ambientales y condiciones mecánicas que ocasionan movimientos en el 
telescopio, observaciones realizadas a lo largo de más de una noche, entre otras.

Al procedimiento de mapear puntos de una imagen a sus correspondientes 
puntos en otra imagen se le llama Registro de imágenes. Esta es una 
transformación espacial que tiene como propósito 
hacer que el conjunto de observaciones coincidan en sus características 
más generales, esto es, alinearlas al mismo sistema de referencia de 
forma que las posiciones de cada estrella coincidan entre cada imagen. 
De no hacer dicho ajuste, la ausencia y presencia de una determinada 
estrella en una posición específica entre distintas imágenes puede ser 
interpretada como variaciones astronómicas. 

Para ejecutar el procedimiento de registro e interpolación, se elige 
una imagen de referencia, la cual debe contener todos nuestros 
objetos de interés en las posiciones que consideremos favorables 
para nuestro propósito. Una observación a tomar en cuenta para beneficio 
de los pasos subsecuentes es procurar que nuestros objetos de especial 
interés no se encuentren muy próximos a los bordes de la imagen. 

Una vez elegida la imagen de referencia, se debe especificar el 
grado del polinomio bidimensional \texttt{process\_config/DEGREE} correspondiente 
al proceso astrométrico de remapeo. Esto implica el mapeo de cada 
píxel de la imagen al sistema de referencia, corrigiendo desplazamientos, 
rotaciones y otras posibles distorsiones ópticas. El polinomio se calcula 
mediante el ajuste de un modelo a las diferencias entre coordenadas 
de estrellas o puntos de referencia comunes en ambas imágenes. Un catálogo 
de dichos objetos es extraído por el programa usando un algoritmo muy 
rápido (alard-old-registration). 
Para registrar todas las imágenes a un marco de referencia, se usa un 
ajuste polinómico 2D. Las coordenadas de los puntos de referencia en la 
imagen fuente $(x, y)$ y en la referencia $(x', y')$ se registran mediante 
una transformación $(x', y') = T(x,y)$
donde $T(x, y)$: 

*ECUACION*

Esta transformación define puntos en la malla entre los puntos de la 
malla original. 

Las imágenes digitales están compuestas por valores discretos, correspondientes 
a píxeles. Sin embargo las transformaciones geométricas pueden generar 
coordenadas no enteras. Es necesaria entonces una interpolación de los 
valores en la malla original para estimar los valores de la imagen en 
la nueva malla de referencia. Esto se logra mediante BICUBIC SPLINES INTERPOLATION, 
el cual utiliza un total de 16 (4x4=) píxeles adyacentes para lograr una 
interpolacion (Han2013/03), obteniendo un resultado suavizado [splines2]. 

% DIAGRAMA BICUBIC INTERPOLATIONS
\figura{Subtraction/bicubic_interp}{width=.5\textwidth}{fig:bicubic-interp;}%
{Diagrama del algoritmo Bicubic Interpolation}


%-------------------------------------------------------------------
\section{Construcción de la imagen de referencia}
%-------------------------------------------------------------------
\label{cap3:sec:reference}

Para la construcción de la imagen de referencia debemos explorar en nuestro 
conjunto de imágenes y seleccionar aproximadamente las 10 de mejor calidad 
en cuanto a seeing y condiciones atmosféricas. Las imágenes seleccionadas 
se listan en el archivo \texttt{register<i>/ref\_list}. Las imágenes tienen diferente 
fondo y diferente seeing. El propósito de la imagen de referencia es 
asemejar las condiciones de cada una de las demás imágenes mediante una 
convolución.

Si bien el paquete cuenta con la opción de construir la imagen de referencia 
mediante una simple adición, este método tiene la principal desventaja de 
que, de haber errores en las imágenes listadas, estos se acumularán 
haciéndose evidentes en la imagen de referencia. 

Es por eso que ISIS incluye con otro procedimiento más recomendado y 
que aprovecha los fundamentos de nuestra implementación de la sustracción 
de imágenes, capaz de lidiar con defectos puntuales en nuestra lista de 
mejores imágenes. Con la intención de construir la imagen de referencia 
como una mediana de cada pixel en la lista de imágenes, primero se 
implementará el mismo procedimiento que se desarrolló para la sustracción 
que se describe más adelante: igualar las condiciones de cada una de las 
imágenes en la lista mediante un kernel de convolución. Respetando así 
los valores de cada imagen independiente y su aporte a la mediana. 
En este caso elegiremos como R (imagen de referencia para la convolución) 
indicando en el parámetro \texttt{REF\_STACK} del archivo \texttt{process\_config}.

Una vez que las imágenes hayan sido transformadas para coincidir con 
la mejor de ellas (la indicada en el \texttt{REF\_STACK}), cada píxel 
a lo largo de todas las imágenes será filtrado mediante 3 sigma 
rejection alrededor de la mediana. Elegimos la mediana en lugar de 
la media ya que funciona mejor para filtrar el tipo de ruido común 
en imágenes astronómicas.

Todo este proceso se realiza ejecutando \texttt{./ref.csh}

%-------------------------------------------------------------------
\section{Sustracción de imágenes}
%-------------------------------------------------------------------
\label{cap3:sec:sustraction}

La sustracción de imágenes es un método que permite emparejar los rasgos más generales 
de una imagen frente a otra mediante distintas técnicas. De forma que puedan ser 
diferenciadas para detectar y medir objetos variables. 

ISIS generaliza para el caso de kernels espacialmente variables sin aumentar el 
costo computacional. Además, impone un escalado constante del flujo entre las 
imágenes (integral del kernel constante), manteniendo una relación fija en el 
brillo de los objetos entre las imágenes. Esto nos asegura que el brillo de los 
objetos se mantenga proporcional en todas las imágenes y garantiza que el ajuste 
del kernel no modifique artificialmente el flujo total.

La esencia del método es encontrar un kernel de convolución K, que transforme 
una imagen de referencia R para ajustarse a una imagen dada I.

Esto se logra mediante el metodo de minimos cuadrados:
$$ \sum_{i}([R \ast K](x_i, y_i) - I(x_i, y_i))^2 $$

Donde el kernel es expresado en sus funciones base (gaussianas para ISIS)
$$ K(u,v) = \sum_{n}a_nK_n(u,v) $$
con 
$$ K_n(u,v)=e^{\frac{-(u^2+v^2)}{2\sigma_k^2}}u_iv_i $$

resolviendo para kernel espacialmente variable:
$$ K(u,v) = \sum_{n}a_n(x,y)K_n(u,v) $$

con los coeficientes $a_n$ siendo funciones polinomiales de $(x, y)$
$$ a_n(x,y) = \sum_{i,j} b_{i,j} x^i y^j$$


En el proceso de alineación del seeing entre las imágenes mediante el kernel de 
convolución, se debe tener especial cuidado en 
que la suma del kernel sea constante. De lo contrario, podría causar que el flujo 
de los objetos en la imagen cambie inesperadamente. 

Un escalado de flujo constante implica que, aunque las imágenes puedan tener 
diferencias en resolución, enfoque, o ruido, se asegura que el flujo total entre 
las imágenes sea proporcional. Esto permite una comparación más directa.

Se impone entonces la restricción de que el flujo total de la imagen no cambie después 
de la transformación. Esto se puede hacer mediante multiplicadores de Lagrange, 
sin embargo resultaría computacionalmente costoso. Es por eso que se opta por  
rediseñar la base de los vectores que forman el kernel (ec. *). 


Separamos un vector base especial $K_0$ que controla el flujo total, de otros 
vectores $K_n'$ encargados de afectar la forma de la transformación, más que 
actuar sobre el brillo y flujo.

%-------------------------------------------------------------------
\section{Detección de variables}

Sin embargo, estos residuos pueden tener su origen debido a una variedad de factores 
no necesariamente astronómicos (pequeños fallos de alineamiento, estrellas saturadas 
o ajuste deficiente de la PSF). Para tener mejor oportunidad de identificar las 
variaciones de nuestro interés, generamos una imagen de medias de diferencias 
(abs.fits o var.fits) donde cada pixel es la mediana del conjunto correspondiente 
de píxeles en cada una de las imágenes de diferencia. De esta forma se reduce 
la influencia de errores sistemáticos, minimizando falsos positivos causados 
por fluctuaciones no astronómicas.

for pixel in fits: mediana(dif1.fits, dif2.fits, ?, dif_n.fits)


%-------------------------------------------------------------------
\section{Fotometría y curvas de luz}
%-------------------------------------------------------------------
\label{cap3:sec:fotometria}


%-------------------------------------------------------------------
%\section*{\NotasBibliograficas}
%-------------------------------------------------------------------
%\TocNotasBibliograficas

%Citamos algo para que aparezca en la bibliografía\ldots
%\citep{ldesc2e}

%\medskip

%Y también ponemos el acrónimo \ac{CVS} para que no cruja.

%Ten en cuenta que si no quieres acrónimos (o no quieres que te falle la compilación en ``release'' mientras no tengas ninguno) basta con que no definas la constante \verb+\acronimosEnRelease+ (en \texttt{config.tex}).


%-------------------------------------------------------------------
%\section*{\ProximoCapitulo}
%-------------------------------------------------------------------
%\TocProximoCapitulo

% Variable local para emacs, para  que encuentre el fichero maestro de
% compilación y funcionen mejor algunas teclas rápidas de AucTeX
%%%
%%% Local Variables:
%%% mode: latex
%%% TeX-master: "../Tesis.tex"
%%% End:
